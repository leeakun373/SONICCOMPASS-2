"""
Sonic Compass - é‡å»ºæ˜Ÿå›¾è„šæœ¬
ç”¨äºåˆæ¬¡è¿è¡Œæˆ–å¼ºåˆ¶é‡å»ºæ•°æ®ç¼“å­˜ï¼ˆå‘é‡ + UMAP åæ ‡ï¼‰
"""

import sys
import os
import time
import numpy as np
from pathlib import Path

# ä¿®å¤ Windows ç»ˆç«¯ç¼–ç é—®é¢˜
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# ç¡®ä¿èƒ½æ‰¾åˆ°æ¨¡å—
sys.path.insert(0, str(Path(__file__).parent))

try:
    import umap
    print("âœ… æ£€æµ‹åˆ° UMAP åº“")
except ImportError:
    print("âŒ æœªæ£€æµ‹åˆ° UMAPï¼è¯·å…ˆè¿è¡Œ: pip install umap-learn scikit-learn matplotlib")
    sys.exit(1)

try:
    from sklearn.preprocessing import LabelEncoder
    SKLEARN_AVAILABLE = True
except ImportError:
    print("âŒ æœªæ£€æµ‹åˆ° scikit-learnï¼è¯·å…ˆè¿è¡Œ: pip install scikit-learn")
    sys.exit(1)

from data import SoundminerImporter
from core import DataProcessor, VectorEngine


def rebuild():
    """é‡å»ºæ˜Ÿå›¾æ•°æ®"""
    print("=" * 60)
    print("ğŸš€ Sonic Compass: æ­£åœ¨é‡ç»˜æ˜Ÿç³»åœ°å›¾ (Rebuilding Atlas)")
    print("=" * 60)
    
    # 1. é…ç½®è·¯å¾„
    DB_PATH = "./test_assets/Sonic.sqlite"
    CACHE_DIR = "./cache"
    
    if not Path(DB_PATH).exists():
        print(f"âŒ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {DB_PATH}")
        print("   è¯·ç¡®ä¿æ•°æ®åº“æ–‡ä»¶å­˜åœ¨äº test_assets/ ç›®å½•")
        sys.exit(1)
    
    # 2. åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶
    print("\nğŸ“¦ åˆå§‹åŒ–å¼•æ“...")
    sys.stdout.flush()  # å¼ºåˆ¶åˆ·æ–°è¾“å‡º
    
    print("   æ­£åœ¨åˆå§‹åŒ– SoundminerImporter...")
    sys.stdout.flush()
    importer = SoundminerImporter(db_path=DB_PATH)
    
    print("   æ­£åœ¨åŠ è½½å‘é‡æ¨¡å‹ï¼ˆè¿™å¯èƒ½éœ€è¦å‡ ç§’é’Ÿï¼‰...")
    sys.stdout.flush()
    vector_engine = VectorEngine(model_path="./models/bge-m3")
    print("   âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
    sys.stdout.flush()
    
    print("   æ­£åœ¨åˆ›å»º DataProcessor...")
    sys.stdout.flush()
    processor = DataProcessor(
        importer=importer,
        vector_engine=vector_engine,
        cache_dir=CACHE_DIR
    )
    print("   âœ… åˆå§‹åŒ–å®Œæˆ")
    sys.stdout.flush()
    
    # 3. å¼ºåˆ¶é‡å»ºï¼ˆè¿™ä¼šè®¡ç®—å‘é‡å’Œ UMAP åæ ‡ï¼‰
    print("\nâš™ï¸  å¼€å§‹è®¡ç®—ï¼ˆè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…ï¼‰...")
    print("   [æ­¥éª¤ 1/4] åŠ è½½æ•°æ®å¹¶è®¡ç®— Category è´¨å¿ƒ...")
    sys.stdout.flush()
    start_time = time.time()
    
    # æ„å»ºç´¢å¼•ï¼ˆå‘é‡åŒ–ï¼‰
    # æ³¨æ„ï¼šbuild_index å†…éƒ¨ä¼šå…ˆè®¡ç®—è´¨å¿ƒï¼Œè¿™ä¸ªè¿‡ç¨‹å¯èƒ½è¾ƒæ…¢
    print("   [æ­¥éª¤ 2/4] å‘é‡åŒ–æ•°æ®ï¼ˆä½¿ç”¨ GPU åŠ é€Ÿï¼‰...")
    sys.stdout.flush()
    metadata, embeddings = processor.build_index(
        limit=None,  # å¤„ç†æ‰€æœ‰æ•°æ®
        force_rebuild=True  # å¼ºåˆ¶é‡å»º
    )
    
    print(f"âœ… å‘é‡åŒ–å®Œæˆ ({len(metadata)} æ¡è®°å½•)")
    print(f"   è€—æ—¶: {time.time() - start_time:.2f} ç§’")
    
    # 4. æå– Category å¹¶ç¼–ç ä¸ºæ ‡ç­¾ï¼ˆä½¿ç”¨ä»²è£åçš„ Categoryï¼‰
    print("\nğŸ·ï¸  æå– Category æ ‡ç­¾ï¼ˆä½¿ç”¨ä»²è£åçš„ Categoryï¼‰...")
    sys.stdout.flush()
    
    # ã€754 CatID Source of Truthã€‘ç›´æ¥ä½¿ç”¨ä»²è£åçš„ Categoryï¼ˆCatShortï¼Œå¦‚ "AIR"ï¼‰
    categories = []
    for meta in metadata:
        # ç›´æ¥ä½¿ç”¨ä»²è£åçš„ Categoryï¼ˆå·²åœ¨ data_processor ä¸­ä¿å­˜ä¸º CatShortï¼‰
        category = meta.get('category', 'UNCATEGORIZED')
        if not category or category == '':
            category = "UNCATEGORIZED"
        categories.append(category)
    
    # ä½¿ç”¨ LabelEncoder ç¼–ç ä¸ºæ•´æ•°æ•°ç»„
    label_encoder = LabelEncoder()
    targets = label_encoder.fit_transform(categories)
    
    print(f"   å‘ç° {len(label_encoder.classes_)} ä¸ª Category")
    print(f"   ç±»åˆ«: {', '.join(label_encoder.classes_[:10])}{'...' if len(label_encoder.classes_) > 10 else ''}")
    
    # 5. Phase 3.5: è®¡ç®— Supervised UMAP åæ ‡ï¼ˆä½¿ç”¨æå¼ºç›‘ç£å‚æ•°ï¼‰
    print("\nğŸ—ºï¸  è®¡ç®— Supervised UMAP åæ ‡ï¼ˆPhase 3.5 æå¼ºç›‘ç£å‚æ•°ï¼‰...")
    coord_start = time.time()
    
    reducer = umap.UMAP(
        n_components=2,
        n_neighbors=50,       # ä»30æå‡åˆ°50 (å¸é™„æ›´å¤šå‘¨å›´çš„ç‚¹)
        min_dist=0.001,       # ä»0.01é™ä½åˆ°0.001 (å…è®¸æåº¦ç´§å¯†)
        spread=0.5,           # é™ä½æ‰©æ•£ (é»˜è®¤1.0)ï¼Œè®©ç¾¤å²›èšæ‹¢
        metric='cosine',      # ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆå¯¹éŸ³é¢‘è¯­ä¹‰æ›´å¥½ï¼‰
        target_weight=0.95,   # ã€å…³é”®ã€‘æå‡åˆ° 0.95ï¼Œå®æ–½é“è…•ç»Ÿæ²»
        target_metric='categorical',  # åˆ†ç±»æ ‡ç­¾
        random_state=42,
        n_jobs=1              # é¿å…å¹¶è¡Œè®¡ç®—å¯¼è‡´çš„å¾®å°å·®å¼‚
    )
    print("   [è¿›åº¦] æ­£åœ¨è¿è¡Œ UMAP fit_transformï¼ˆè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰...")
    sys.stdout.flush()
    coords_2d = reducer.fit_transform(embeddings, y=targets)
    print("   [è¿›åº¦] UMAP è®¡ç®—å®Œæˆ")
    sys.stdout.flush()
    
    # åæ ‡å½’ä¸€åŒ–åˆ° 0-3000 èŒƒå›´ï¼ˆå‡å°‘"æµ·æ´‹"ç©ºéš™ï¼‰
    min_coords = coords_2d.min(axis=0)
    max_coords = coords_2d.max(axis=0)
    scale = 3000.0 / (np.max(max_coords - min_coords) + 1e-5)
    coords_2d = (coords_2d - min_coords) * scale
    
    # ä¿å­˜åæ ‡
    processor.save_coordinates(coords_2d)
    
    print(f"âœ… åæ ‡è®¡ç®—å®Œæˆ")
    print(f"   è€—æ—¶: {time.time() - coord_start:.2f} ç§’")
    print(f"   åæ ‡èŒƒå›´: [{coords_2d.min(axis=0)[0]:.1f}, {coords_2d.min(axis=0)[1]:.1f}] åˆ° [{coords_2d.max(axis=0)[0]:.1f}, {coords_2d.max(axis=0)[1]:.1f}]")
    
    # 5. å®Œæˆ
    total_time = time.time() - start_time
    print("\n" + "=" * 60)
    print(f"âœ… æ˜Ÿå›¾æ„å»ºå®Œæˆï¼")
    print(f"   æ€»è€—æ—¶: {total_time:.2f} ç§’")
    print(f"   æ•°æ®é‡: {len(metadata)} æ¡è®°å½•")
    print(f"   åæ ‡å·²ä¿å­˜è‡³: {os.path.join(CACHE_DIR, 'coordinates.npy')}")
    print("=" * 60)
    print("\nğŸ‘‰ ç°åœ¨å¯ä»¥è¿è¡Œ: python main.py")


if __name__ == "__main__":
    rebuild()

