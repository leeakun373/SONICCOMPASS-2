# 数据处理工作流说明

## 概述

Sonic Compass 提供了多个数据处理脚本，用于不同的场景和需求。

## 工作流分类

### 1. 完整重建流程 (Full Rebuild)

**脚本**: `rebuild_atlas.py`

**功能**: 
- 重新向量化所有数据（使用GPU加速）
- 计算Category质心（用于AI语义仲裁）
- 计算Supervised UMAP坐标
- 保存所有缓存文件

**适用场景**:
- 首次运行
- 数据库更新（新增/删除文件）
- 向量模型更新
- 需要重新计算质心

**耗时**: 最长（取决于数据量，通常10-30分钟）

**输出文件**:
- `cache/metadata.pkl` - 元数据
- `cache/embeddings.npy` - 向量矩阵
- `cache/coordinates.npy` - UMAP坐标

---

### 2. 仅重新计算UMAP坐标 (UMAP Recalculation Only)

**脚本**: `recalculate_umap.py`

**功能**:
- 加载现有向量缓存（不重新向量化）
- 使用新参数重新计算UMAP坐标
- 仅更新坐标文件

**适用场景**:
- 调整UMAP参数（n_neighbors, min_dist等）
- 快速测试不同参数效果
- 向量数据未变化，只需更新布局

**耗时**: 中等（通常2-5分钟，取决于数据量）

**前提条件**:
- 必须存在 `cache/metadata.pkl` 和 `cache/embeddings.npy`

**输出文件**:
- `cache/coordinates.npy` - 更新的UMAP坐标

---

### 3. 仅重新向量化 (Vectors Rebuild Only)

**脚本**: `rebuild_vectors_only.py`

**功能**:
- 重新向量化所有数据
- 保留现有UMAP坐标（但会失效）

**适用场景**:
- 向量模型更新
- 需要重新计算质心
- **注意**: 向量化后必须重新计算UMAP坐标

**耗时**: 较长（通常5-20分钟）

**警告**: 
- 向量化完成后，现有UMAP坐标将不再匹配
- 必须随后运行 `recalculate_umap.py`

**输出文件**:
- `cache/metadata.pkl` - 更新的元数据
- `cache/embeddings.npy` - 更新的向量矩阵

---

## 工作流选择指南

### 场景1: 首次运行
```
python rebuild_atlas.py
```

### 场景2: 调整UMAP参数（已有向量缓存）
```
python recalculate_umap.py
```

### 场景3: 数据库更新（新增文件）
```
python rebuild_atlas.py  # 完整重建
```

### 场景4: 向量模型更新
```
python rebuild_vectors_only.py  # 重新向量化
python recalculate_umap.py      # 重新计算坐标
```

### 场景5: 仅测试UMAP参数效果
```
python recalculate_umap.py  # 快速迭代
```

---

## 软件内按钮

在软件UI中，提供了两个按钮：

1. **🔄 Rebuild Atlas (Full)**
   - 对应 `rebuild_atlas.py`
   - 完整重建流程
   - 在后台线程执行，UI不卡死

2. **🔄 Recalc UMAP Only**
   - 对应 `recalculate_umap.py`
   - 仅重新计算坐标
   - 在后台线程执行，UI不卡死

---

## 参数说明

### UMAP参数（当前设置）

- `n_neighbors=50`: 增强全局结构，吸附更多周围的点
- `min_dist=0.001`: 允许极度紧密堆积，形成紧凑大陆
- `spread=0.5`: 降低扩散，让群岛聚拢
- `target_weight=0.95`: 95%依赖分类标签，实施铁腕统治
- `target_metric='categorical'`: 适用于离散分类标签

### 自动质心生成

- `rebuild_atlas.py` 会自动检查并生成 Platinum Centroids（如果缓存不存在）
- 质心文件：`cache/platinum_centroids_754.pkl`
- 包含 753 个标准 UCS CatID 定义向量

### 坐标归一化

- 范围: `0-3000`
- 目的: 减少"海洋"空隙，让数据更紧凑

---

## 性能对比

| 工作流 | 向量化 | UMAP计算 | 总耗时 | 适用场景 |
|--------|--------|----------|--------|----------|
| Full Rebuild | ✅ | ✅ | 10-30分钟 | 首次/数据库更新 |
| UMAP Only | ❌ | ✅ | 2-5分钟 | 参数调整 |
| Vectors Only | ✅ | ❌ | 5-20分钟 | 模型更新 |

---

---

### 4. 微缩验证工具 (Subset Verification)

**脚本**: `tools/verify_subset.py`

**功能**:
- 从数据库查询包含特定关键词的数据（快速提取子集）
- **使用与正式流程完全相同的分类逻辑**（`_extract_category`）
- 生成 UMAP 可视化散点图
- 打印详细的分类报告（分类来源统计、类别分布、坐标信息）
- **导出 CSV 文件**（包含文件名、CatID、主类别、坐标等详细信息）

**适用场景**:
- 更新 `ucs_alias.csv` 后，快速验证分类效果
- 调试分类逻辑，查看特定关键词的分类结果
- 测试新添加的关键词映射是否生效
- **验证聚类效果**：检查同一主类别（如 WEAPON）下的数据是否在坐标上聚集
- 验证 AI 预测的准确率

**耗时**: 很短（通常 10-30 秒，取决于数据量）

**使用方法**:
```bash
# 基本用法
python tools/verify_subset.py AIR

# 指定参数
python tools/verify_subset.py WEAPON --limit 100 --output verify_weapon.png

# 完整参数
python tools/verify_subset.py SCIFI --limit 200 --db ./test_assets/Sonic.sqlite --output verify_scifi.png
```

**参数说明**:
- `keyword`（必需）: 搜索关键词，会在 filename、description、keywords 中搜索
- `--limit`（可选）: 最大返回数量，默认 500
- `--db`（可选）: 数据库路径，默认 `./test_assets/Sonic.sqlite`
- `--output`（可选）: 输出图片路径，默认 `verification_result.png`

**输出**:
1. **PNG 图片**：UMAP 散点图
   - X轴：UMAP 维度 1（语义空间位置）
   - Y轴：UMAP 维度 2（语义空间位置）
   - 不同主类别用不同颜色标记
   - **聚类效果验证**：同一主类别的数据应该在坐标上聚集（形成"大陆"）

2. **CSV 文件**：`verify_{keyword}_details.csv`
   - 包含所有数据的详细信息
   - 列：序号、文件名、CatID、主类别、分类来源、UMAP_X、UMAP_Y、Rich Text
   - 可以用 Excel 打开，方便查看和排序

3. **控制台报告**：
   - 分类来源统计（Level -1, 0, 1, 2 各有多少）
   - 主类别分布（每个主类别有多少条）
   - CatID 分布（每个 CatID 有多少条）
   - 详细结果（前20条，包含坐标信息）

**与正式流程的关联性**:
- ✅ **使用相同的分类逻辑**：调用 `DataProcessor._extract_category()`，与正式流程完全一致
- ✅ **使用相同的规则文件**：读取 `data_config/rules.json`（由 `generate_rules_json.py` 生成）
- ✅ **使用相同的质心文件**：加载 `cache/platinum_centroids_754.pkl`（用于 AI 预测）
- ✅ **使用相同的 UCS Manager**：验证和规范化逻辑完全一致

**测试目的**:
- **验证分类准确性**：检查文件是否正确分类到预期的 CatID
- **验证聚类效果**：检查同一主类别下的数据是否在 UMAP 坐标上聚集
- **验证规则生效**：检查 Level 0（规则）的命中率
- **验证 AI 预测**：检查 Level 2（AI 预测）的准确率

**优势**:
- ✅ 快速验证，无需运行全量构建（10-30 秒 vs 10-30 分钟）
- ✅ 可视化结果，直观查看分类效果和聚类分布
- ✅ 详细报告，了解分类来源分布
- ✅ CSV 导出，方便在 Excel 中分析和排序
- ✅ 与正式流程完全一致，测试结果可靠

---

## 数据维护完整流程

### 场景：更新关键词映射并验证效果

当你更新了 `ucs_alias.csv` 文件后，需要以下步骤来让更改生效并验证效果：

#### 步骤 1: 标准化 CSV 文件（可选但推荐）

```bash
python tools/standardize_alias_csv.py
```

**作用**:
- 验证 CSV 格式是否正确
- 验证所有 CatID 是否有效
- 规范化 CatID 格式（保持官方 UCS 格式）

**输出**:
- 标准化的 `data_config/ucs_alias.csv`
- 备份文件：`data_config/ucs_alias.csv.backup`
- 警告信息：列出所有无效的 CatID（带行号）

---

#### 步骤 2: 生成规则文件

```bash
python tools/generate_rules_json.py
```

**作用**:
- 从 `ucs_alias.csv` 读取关键词映射
- 归一化关键词（保留空格）
- 验证 CatID 有效性
- 按关键词长度降序排序
- 生成 `data_config/rules.json`

**输出**:
- `data_config/rules.json` - 供 Level 0（强规则）使用
- 警告信息：列出所有无效的 CatID

**重要**: 
- ⚠️ 更新 CSV 后，**必须**运行此脚本重新生成 `rules.json`
- 否则分类系统仍会使用旧的规则

---

#### 步骤 3: 更新质心定义（可选）

如果你修改了 `data_config/ucs_definitions.json`（UCS 类别定义），需要重新生成质心：

```bash
python tools/generate_platinum_centroids.py
```

**作用**:
- 从 `ucs_definitions.json` 生成 753 个 UCS CatID 的向量质心
- 用于 Level 2（AI 预测）

**输出**:
- `cache/platinum_centroids_754.pkl` - 质心文件

**何时需要**:
- 修改了 UCS 类别定义
- 添加了新的 CatID 描述
- 需要更新 AI 对类别的理解

---

#### 步骤 4: 快速验证（推荐）

使用微缩验证工具快速测试几个关键词：

```bash
# 验证几个大类
python tools/verify_subset.py AIR --limit 100
python tools/verify_subset.py WEAPON --limit 100
python tools/verify_subset.py VEHICLE --limit 100
```

**检查要点**:
1. **分类来源统计**：
   - Level -1（文件名短路）比例：如果文件名包含 CatID，应该被识别
   - Level 0（规则）比例是否提高？
   - Level 2（AI 预测）比例是否降低？
   - 如果 Level 0 比例太低，说明需要添加更多关键词映射

2. **主类别分布**：
   - 是否正确分类到预期的主类别（如 WEAPON, LASERS）？
   - 是否有大量 "UNCATEGORIZED"？
   - 如果有很多 "UNCATEGORIZED"，说明关键词映射不够

3. **聚类效果验证**（关键）：
   - 打开生成的 CSV 文件（`verify_{keyword}_details.csv`）
   - 按主类别排序，查看 UMAP_X 和 UMAP_Y 坐标
   - **同一主类别的数据应该在坐标上聚集**（X 和 Y 值相近）
   - 如果同一主类别的数据分散，说明聚类效果需要改进
   - 示例：所有 WEAPON 相关的数据应该在坐标 (5, 10) 附近聚集，而不是分散在 (1, 2), (8, 15), (3, 20) 等不同位置

4. **详细结果**：
   - 查看前20条数据的分类结果
   - 检查 rich_text 内容是否正确
   - 确认分类来源是否正确
   - 查看坐标分布，验证聚类效果

---

#### 步骤 5: 全量构建（验证通过后）

如果快速验证效果良好，运行全量构建：

```bash
python rebuild_atlas.py
```

**作用**:
- 重新向量化所有数据
- 重新计算 UMAP 坐标
- 应用新的分类规则

**耗时**: 10-30 分钟（取决于数据量）

---

### 完整工作流示例

假设你要添加新的关键词映射并验证 WEAPON 类别的聚类效果：

```bash
# 1. 编辑 CSV 文件（手动或使用 LLM）
# 在 data_config/ucs_alias.csv 中添加新行：
# laser gun, LASRGun
# magic fireball, MAGCFIRE
# sword hit, WEAPSwrd

# 2. 标准化 CSV（验证格式）
python tools/standardize_alias_csv.py

# 3. 生成规则文件
python tools/generate_rules_json.py

# 4. 快速验证（测试新添加的关键词）
python tools/verify_subset.py WEAPON --limit 100 --output verify_weapon.png

# 5. 检查验证结果：
#    - 查看控制台报告：分类来源统计、主类别分布
#    - 查看 PNG 图片：检查 WEAPON 相关的数据是否在坐标上聚集
#    - 打开 CSV 文件（verify_WEAPON_details.csv）：
#      * 按主类别排序
#      * 检查 UMAP_X 和 UMAP_Y 坐标
#      * 验证同一主类别的数据是否聚集（坐标相近）

# 6. 如果验证通过，运行全量构建
python rebuild_atlas.py
```

### UMAP 坐标说明

**坐标含义**:
- **X轴（UMAP 维度 1）**: 降维后的第一个维度，表示数据在语义空间中的位置
- **Y轴（UMAP 维度 2）**: 降维后的第二个维度，表示数据在语义空间中的位置
- **坐标范围**: 通常为 -10 到 10 之间（取决于 UMAP 参数和数据集）

**聚类效果验证**:
- **理想情况**: 同一主类别（如 WEAPON）的数据应该在坐标上聚集，形成"大陆"
- **验证方法**:
  1. 打开 CSV 文件，按主类别排序
  2. 查看同一主类别的 UMAP_X 和 UMAP_Y 值
  3. 计算坐标的方差或标准差
  4. 如果方差小，说明聚类效果好（数据聚集）
  5. 如果方差大，说明聚类效果差（数据分散）

**示例**:
```
主类别: WEAPON
- 文件1: CatID=WEAPSwrd, 坐标=(5.2, 10.1)
- 文件2: CatID=WEAPArmr, 坐标=(5.5, 10.3)
- 文件3: CatID=WEAPWhip, 坐标=(5.1, 9.8)
→ 坐标相近，聚类效果好 ✅

主类别: WEAPON
- 文件1: CatID=WEAPSwrd, 坐标=(1.2, 2.1)
- 文件2: CatID=WEAPArmr, 坐标=(8.5, 15.3)
- 文件3: CatID=WEAPWhip, 坐标=(3.1, 20.8)
→ 坐标分散，聚类效果差 ❌
```

---

### 数据维护检查清单

在更新数据后，使用以下清单确保所有步骤都完成：

- [ ] 更新 `data_config/ucs_alias.csv`（添加/修改关键词映射）
- [ ] 运行 `standardize_alias_csv.py` 验证格式
- [ ] 运行 `generate_rules_json.py` 生成规则文件
- [ ] （可选）更新 `ucs_definitions.json` 并重新生成质心
- [ ] 使用 `verify_subset.py` 快速验证几个关键词
- [ ] 检查验证报告，确认分类效果
- [ ] 如果效果良好，运行 `rebuild_atlas.py` 全量构建
- [ ] 启动软件，查看最终效果

---

## 注意事项

1. **缓存一致性**: 
   - 向量和坐标必须匹配
   - 如果只更新向量，必须重新计算坐标

2. **规则更新**:
   - 更新 `ucs_alias.csv` 后，**必须**运行 `generate_rules_json.py`
   - 否则分类系统仍会使用旧的规则

3. **验证流程**:
   - 建议先使用 `verify_subset.py` 快速验证
   - 确认效果后再运行全量构建
   - 可以节省大量时间

4. **内存占用**:
   - UMAP计算时，`n_neighbors=30` 比 `n_neighbors=15` 占用更多内存
   - 大数据集（>100万条）可能需要调整参数

5. **线程安全**:
   - 软件内的重建操作在后台线程执行
   - 不会阻塞UI

6. **进度反馈**:
   - 所有操作都有进度条显示
   - 关键步骤会输出日志

